Idea：
把数据区分为重要部分和大数据部分。
重要部分含有数据的重要索引分类信息，并且对数据的操作有重要意义。
大数据部分通常是无意义的， 但是和重要数据相关联。这些数据并不需要存储在数据库的快速索引部分，而只需要存储于某个类似于CDN的服务器之上， 通过重要数据的索引进行访问即可。

特色：
让数据库节点可以自己解决重新分配工作问题。重新分配可以分为三步：
需要重新分配的时候，在后台进行准备新的节点
默默地把数据拷贝到新的节点， 拷贝一点，forward一点，保持所有复制节点同步
达到一定规模以后，通知路由器，修改路由

用例：
数据太大， 需要分裂
数据太忙， 需要多个节点共同分担
数据危险性大或者安全要求高， 需要更多的备份

Idea：
自适应的大数据存储方案。可以采用不同的存储方式，引用存储，引用加增量，等等

Data的特性：
大小，访问频度，更新频度，性能要求，复杂性
根据数据的特性，可以进化出不同的存储群，以适应用户的需求

数据的关联：
有些数据必须在一起，或者离得比较近，所以要求一些存储群要物理上保存在较近的位置，便于用户一次同时取出，或者在本地进行计算后取得结果。比较远的节点由于性能差逐渐被淘汰，或者逐渐搬家到近处。

分为灾难性应激和非灾难性进化
一群节点互相比拼，更有效的节点会有机会把基因扩散到其他节点，用神经网络学习来决定两个节点的相似性

network connection:

1. Use udp not tcp to speed up
2. Udp send, wait for udp response, if no response is issued, send again or try another server
3. All udp packages will have a tracking id, if some of them are missing, retry with the id

